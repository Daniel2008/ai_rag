# 功能详解

本文档详细介绍智汇 RAG 的各项功能。

## 目录

- [知识库管理](#知识库管理)
- [智能检索](#智能检索)
- [对话问答](#对话问答)
- [文档生成](#文档生成)
- [设置配置](#设置配置)

---

## 知识库管理

### 文档导入

#### 支持的文件格式

| 格式         | 扩展名           | 解析器       |
| ------------ | ---------------- | ------------ |
| PDF          | .pdf             | pdf-parse    |
| Word         | .docx            | officeparser |
| PowerPoint   | .pptx            | officeparser |
| Excel        | .xlsx            | officeparser |
| OpenDocument | .odt, .odp, .ods | officeparser |
| 纯文本       | .txt             | 直接读取     |
| Markdown     | .md              | 直接读取     |

#### 导入方式

1. **文件上传**: 点击上传按钮或拖拽文件到知识库面板
2. **URL 导入**: 输入网页链接，自动抓取内容

#### 导入流程

```
文件选择 → 文档解析 → 内容分块 → 向量嵌入 → 存储入库
   │          │          │          │          │
   5%        15%        25%        70%       100%
```

### 文档集管理

文档集允许你按主题组织相关文档：

- **创建文档集**: 点击"+"按钮，输入名称和描述
- **添加文档**: 选择要加入的文档
- **编辑文档集**: 修改名称、描述或包含的文档
- **删除文档集**: 移除文档集（不会删除实际文档）

#### 使用场景

- 按项目组织技术文档
- 按主题分类研究论文
- 按时间分组会议记录

### 文档操作

#### 重新索引

当文档内容更新后，点击"重新索引"按钮：

1. 清除旧的向量数据
2. 重新解析文档
3. 生成新的向量嵌入
4. 更新索引

#### 移除文档

从知识库中删除文档：

1. 删除向量存储中的记录
2. 删除元数据记录
3. 从所有文档集中移除

#### 刷新知识库

增量更新知识库：

- 扫描文件变更
- 重新索引已修改的文件
- 删除已不存在的文件记录

#### 重建所有索引

完全重建知识库索引：

- 清空现有向量存储
- 重新处理所有已记录的文件
- 适用于切换嵌入模型后

---

## 智能检索

### 检索策略

智汇 RAG 使用混合检索策略，结合多种技术提高召回率和精度。

#### 1. 向量语义搜索

基于文本含义进行检索：

```
用户查询 → 向量化 → 相似度计算 → 返回最相似文档
```

**优点**: 理解语义，可以匹配同义词和相关概念
**场景**: "解释一下这个功能的原理"

#### 2. BM25 关键词搜索

基于关键词匹配的经典算法：

```
用户查询 → 分词 → TF-IDF 计算 → BM25 评分 → 返回最相关文档
```

**优点**: 精准匹配专有名词、代码、缩写
**场景**: "LanceDB API 使用方法"

#### 3. RRF 融合排序

Reciprocal Rank Fusion 算法合并多路召回：

```typescript
RRF_score(d) = Σ 1 / (k + rank(d))

// k = 60 (默认)
// rank(d) 为文档 d 在各召回列表中的排名
```

**效果**: 综合语义相关性和关键词匹配

#### 4. MMR 去重

Maximal Marginal Relevance 提高结果多样性：

```typescript
MMR = λ * similarity(q, d) - (1 - λ) * max(similarity(d, d_i))

// λ = 0.75 (偏向相关性)
```

**效果**: 避免返回内容高度相似的文档

#### 5. Rerank 重排序（可选）

使用重排序模型精排结果：

- 模型: bge-reranker-base
- 对初步召回结果进行细粒度评分
- 提高最终结果的精度

### 检索配置

| 配置项       | 默认值 | 说明                     |
| ------------ | ------ | ------------------------ |
| 检索数量 (k) | 6      | 返回的文档数量           |
| 相关性阈值   | 0.25   | 过滤低相关性结果         |
| 向量权重     | 0.6    | 向量搜索在融合中的权重   |
| BM25 权重    | 0.4    | 关键词搜索在融合中的权重 |
| RRF K        | 60     | RRF 算法参数             |
| MMR Lambda   | 0.75   | MMR 多样性参数           |

### 检索范围

#### 全库检索

默认模式，搜索整个知识库。

#### 文档集检索

限定在选定的文档集内搜索。

#### 指定文件检索

使用 `#` 语法指定文件：

```
#文件名 问题内容
```

---

## 对话问答

### 对话界面

#### 消息类型

- **用户消息**: 用户输入的问题
- **AI 回答**: 助手生成的回答
- **来源引用**: 回答所参考的文档片段

#### 消息操作

- **复制**: 复制消息内容
- **重试**: 重新生成回答
- **查看来源**: 展开引用的原文

### 对话记忆

每个对话会话独立维护历史记录：

```typescript
interface Message {
  role: 'user' | 'ai' | 'system'
  content: string
  sources?: Source[] // 引用来源
  suggestions?: string[] // 推荐问题
}
```

历史消息会影响后续回答的上下文理解。

### 流式输出

AI 回答实时流式输出：

1. 前端发送问题
2. 后端检索相关文档
3. 构建 Prompt
4. 调用 LLM 流式生成
5. 逐 token 发送到前端
6. 前端实时渲染

### 推荐问题

每次回答后，AI 会生成相关的后续问题：

```json
{
  "suggestions": ["这个功能是如何实现的？", "还有哪些相关的配置选项？", "能举一个具体的例子吗？"]
}
```

### 会话管理

#### 新建会话

点击"+"按钮创建新对话。

#### 会话列表

- 按时间排序显示
- 支持重命名
- 支持删除
- 支持收藏（星标）

#### 会话标题

首次提问后自动根据问题生成标题。

---

## 文档生成

### Word 文档生成

基于知识库内容生成 Word 文档：

1. 输入主题或大纲
2. AI 检索相关知识
3. 生成结构化内容
4. 导出为 .docx 文件

#### 文档结构

```
├── 标题
├── 摘要
├── 目录
├── 章节 1
│   ├── 内容
│   └── 小节
├── 章节 2
│   └── ...
└── 参考来源
```

### PPT 演示文稿生成

基于知识库内容生成 PowerPoint：

1. 输入演示主题
2. AI 规划演示结构
3. 生成各页内容
4. 导出为 .pptx 文件

#### 幻灯片类型

- 标题页
- 内容页（标题 + 要点）
- 图表页（如有数据）
- 总结页

---

## 设置配置

### AI 模型配置

#### OpenAI

```yaml
服务商: OpenAI
API Key: sk-xxx
模型: gpt-4 / gpt-3.5-turbo
API 地址: https://api.openai.com/v1 (可自定义)
```

#### Anthropic Claude

```yaml
服务商: Anthropic
API Key: sk-xxx
模型: claude-3-opus / claude-3-sonnet
```

#### Ollama 本地模型

```yaml
服务商: Ollama
API 地址: http://localhost:11434
模型: llama2 / mistral / qwen 等
```

### 嵌入模型配置

#### 本地嵌入（推荐）

使用 HuggingFace 模型，完全离线：

```yaml
提供者: local
模型: BAAI/bge-small-zh-v1.5
维度: 512
```

#### OpenAI 嵌入

使用 OpenAI API：

```yaml
提供者: openai
模型: text-embedding-ada-002
```

> 注意: 切换嵌入模型后需要重建索引

### RAG 配置

| 配置项     | 说明                 | 默认值 |
| ---------- | -------------------- | ------ |
| 检索数量   | 每次检索返回的文档数 | 6      |
| 相关性阈值 | 过滤低分结果         | 0.25   |
| 混合检索   | 启用 BM25 + 向量     | 开启   |
| 多查询扩展 | 扩展查询变体         | 关闭   |
| 重排序     | 使用 Rerank 模型     | 关闭   |

### 界面配置

- **主题**: 跟随系统 / 浅色 / 深色
- **侧边栏**: 显示/隐藏对话列表
- **知识库面板**: 显示/隐藏知识库

---

## 快捷键

| 快捷键          | 功能                   |
| --------------- | ---------------------- |
| `Enter`         | 发送消息               |
| `Shift + Enter` | 换行                   |
| `Ctrl + N`      | 新建对话               |
| `F12`           | 开发者工具（开发模式） |

---

## 最佳实践

### 文档导入建议

1. **优先使用原生格式**: PDF/DOCX 比图片扫描件效果更好
2. **保持文档结构**: 使用标题、段落等格式化
3. **避免过大文件**: 单文件建议不超过 100MB
4. **定期更新索引**: 文档修改后及时重建索引

### 提问技巧

1. **明确具体**: "如何配置 X 功能？" 优于 "怎么用？"
2. **限定范围**: 使用 `#文件名` 指定来源
3. **分步提问**: 复杂问题拆解为多个简单问题
4. **利用上下文**: 在同一会话中追问

### 性能优化

1. **控制知识库大小**: 删除不需要的文档
2. **使用本地嵌入**: 减少网络延迟
3. **合理设置检索数量**: 一般 6-10 个即可
4. **启用增量更新**: 避免全量重建索引
